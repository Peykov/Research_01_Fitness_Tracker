{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Feature engineering is the process of transforming raw data into meaningful features that can be used for machine learning. This involves selecting the most useful features from the raw data and using them to build or create new features that represent the information in the dataset in a more effective way. These new, engineered features can make it easier for machine learning models to learn from the data and make more accurate predictions when done righ\n",
    "Examples\n",
    "\n",
    "•Alter existing data\n",
    "\n",
    "•Use domain knowledge\n",
    "\n",
    "•Numerical features\n",
    "\n",
    "•Temporal features\n",
    "\n",
    "•Frequency features\n",
    "\n",
    "•Principle component analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Butterworth low-pass filter\n",
    "\n",
    "A Butterworth low-pass filter is a type of filter that is used to remove high frequency noise from a dataset. It is most commonly used in machine learning in order to improve the accuracy of the model. The filter works by removing any data points above a certain threshold frequency, while still preserving the underlying pattern of the data. By doing so, it helps to reduce the effect of noise on the model, which can lead to better results.\n",
    "\n",
    "![Alt text](img/image-5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal component analysis (PCA)\n",
    "\n",
    "PCA is a technique used in machine learning to reduce the complexity of data by transforming the data into a new set of variables called principal components. This transformation is done in such a way that the new set of variables captures the most amount of information from the original data set, while reducing the number of variables necessary. This helps to reduce the complexity of the data and make it easier to analyze and make predictions from.\n",
    "\n",
    "![Alt text](img/image-6.png)\n",
    "\n",
    "### Elbow technique\n",
    "\n",
    "The elbow technique is a method used to determine the optimal number of components to use when conducting a PCA. It works by testing multiple different component numbers and then evaluating the variance captured by each component number. The optimal component number is then chosen as the number of components that capture the most variance while also not incorporating too many components. This is done by plotting the variance captured against the component number and then selecting the point at which the rate of change in variance diminishes (the \"elbow\"), as this is typically the point at which adding more components does not significantly improve the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of squares\n",
    "\n",
    "To further exploit the data, the scalar magnitudes r of the accelerometer and gyroscope were calculated. r is the scalar magnitude of the three combined data points: x, y, and z. The advantage of using r versus any particular data direction is that it is impartial to device orientation and can handle dynamic re-orientations. r is calculated by:\n",
    "\n",
    "$$ r_{magnitude} = \\sqrt{x^2 + y^2 + z^2} $$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal abstraction (Rolling Avergaes)\n",
    "\n",
    "![Alt text](img/image-7.png)\n",
    "\n",
    "https://datagy.io/rolling-average-pandas/\n",
    "\n",
    "![Alt text](img/image-8.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Fourier Transformation (DFT)\n",
    "The idea of a Fourier transformation is that any sequence of measurements we perform can be represented by a combination of sinusoid functionswith different frequencies\n",
    "A DFT is beneficial for Machine Learning, as it can be used to represent data in terms of frequency components, allowing for more efficient analysis of the data. This provides a way to better understand and model complex data sets, as the frequency components produced by the DFT can provide insight into patterns and trends that would not otherwise be visible. Additionally, the DFT can be used to reduce noise, allowing for more accurate models.\n",
    "\n",
    "Features we will be extracting:\n",
    "\n",
    "• Amplitude (for each of the relevant frequencies that are part of the time window)\n",
    "• Max frequency\n",
    "• Weighted frequency (average)\n",
    "• Power spectral entropy\n",
    "\n",
    "![Alt text](image-1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering\n",
    "\n",
    "K-means clustering is an unsupervised machine learning algorithm used to group data into clusters based on similarity. It randomly initializes k points (centroids) in the data space, calculates the distance between each data point and each centroid, and assigns each point to its closest centroid. K-means clustering is a popular feature engineering technique used in many applications such as identifying the most important features in a dataset, segmenting customers into different clusters based on their purchase behaviors, anomaly detection, and image compression.\n",
    "\n",
    "The Elbow Method, also known as the “elbow curve technique”, is used to determine the optimal number of clusters for a given dataset. It plots the Inertia (sum of squared distances of samples to their closest cluster center) for each k (number of clusters) against k and looks for the “elbow” point in the plot; this point represents the optimal number of clusters. The elbow method works by looping through different values of k and calculating the sum of squared errors for each iteration.\n",
    "\n",
    "![Alt text](image.png)\n",
    "\n",
    "https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
